<p align="center">
  <img src="images/logo.png" alt="SkillForge-VR Logo" width="200"/>
</p>

# SkillForge-VR

An immersive, AI-powered PCVR application for Technical and Vocational Education and Training (TVET), built for the IEEE Metaverse Competition. SkillForge-VR uses a voice-first interface so beginners can learn hands-on trades in natural language without wrestling with complex VR menus.

---

## ğŸš© Problem
- Traditional VR training relies on complex UIs that overwhelm beginners.
- Traditional vocational training in Nigeria is often static, language-limited, and difficult to scale.
- Learners struggle to connect theory to hands-on practice.
- The formal system rarely accommodates diverse learning paces and individual learning patterns.
- Language barriers hinder access because training is not delivered in local languages (Hausa, Igbo, Yoruba), unlike real workshops.

---

## ğŸ’¡ Solution

SkillForge-VR combines adaptive AI with a voice-first VR interface:

- Primary input: Voice (VUI) â€” players interact mainly by speaking; controllers are optional/fallback.
- PCVR support â€” optimized for PC-based VR headsets for high-fidelity simulation.
- Adaptive AI Tutors â€” adjust difficulty, pace, and learning paths in real time.
- Career Guidance Lobby â€” an AI mentor aligns interests to specific TVET sub-fields.
- Workshop Simulations â€” AI Instructors guide step-by-step practice (e.g., carpentry, welding, tailoring, mechanics).
- Multilingual â€” Hausa, Igbo, Yoruba (plus English).
- Gamification â€” tasks, levels, rewards, and progress tracking to sustain engagement.
- For all ages â€” suitable for children and adults.

---

## ğŸ—£ï¸ Voice-First Interaction (AI-Powered VUI)

Players interact using natural language; the AI understands intent, confirms steps, and adapts responses contextuallyâ€”far beyond simple phrase matching.

- Activation:
  - Push-to-talk: Hold the controller trigger (or mapped key) while speaking.
- AI Confirmation:
  - The system confirms recognized commands and next steps, clarifies ambiguous requests, and guides users interactively.
- Feedback:
  - Spoken responses via TTS with on-screen captions/subtitles.
  - Visual highlights on referenced objects and steps.
- Disambiguation:
  - If multiple objects match a command, the AI numbers/highlights candidates and prompts for selection 
- Fallback:
  - Simple controller/gaze click for confirm/cancel, tool pick-up, and locomotion in noisy environments.


### Example voice intents

- Navigation:
  - â€œOpen the carpentry workshopâ€
  - â€œGo back to the lobbyâ€
  - â€œStart level twoâ€
- Learning flow:
  - â€œBegin the safety briefingâ€
  - â€œRepeat that stepâ€ / â€œGo slowerâ€ / â€œSkip this stepâ€
  - â€œWhat did I do wrong?â€ / â€œShow me the correct techniqueâ€
- Workshop actions:
  - â€œSelect the measuring tapeâ€ / â€œClamp the woodâ€
  - â€œCalibrate the welderâ€ / â€œLower the voltage to 18â€
  - â€œStart the sewing machineâ€
- Meta and control:
  - â€œPause trainingâ€ / â€œResumeâ€
  - â€œSave my progressâ€ / â€œShow my progressâ€
  - â€œOpen the checklistâ€ / â€œShow hintsâ€
- Language:
  - â€œSwitch to Yorubaâ€ / â€œSpeak in Igboâ€ / â€œUse Hausaâ€
- Accessibility:
  - â€œEnable captionsâ€ / â€œIncrease text sizeâ€

### VUI pipeline (high level)

- ASR (speech-to-text) captures the userâ€™s voice.
- NLU maps utterances to intents and parameters given scene context.
- Orchestrator triggers VR actions and AI Instructor responses.
- TTS (text-to-speech) delivers multilingual audio with captions.

Latency targets: <500 ms for command-and-control; longer for complex tutoring responses.

---

## ğŸ›  Workflow

1. VR Lobby
   - AI Career Guide: Discuss interests; get tailored TVET recommendations.
   - Workshops: Pick a trade and start guided practice.
     
  Demo: [SkillForge-VR in action](https://www.youtube.com/watch?v=ltrWb-F3pUQ&t=10s)

<p align="center">
  <iframe width="560" height="315" 
    src="https://www.youtube.com/embed/ltrWb-F3pUQ?start=10" 
    title="SkillForge-VR Demo" 
    style="border:0;" 
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
    allowfullscreen>
  </iframe>
</p>



2. AI Career Guide
   - Conversational intake about passions, skills, and constraints.
   - Mentor explains trade-offs, market demand, and learning paths.

3. Workshop Learning
   - AI Instructor assigns tasks and provides step-by-step guidance.
   - Real-time adaptation based on performance and voice feedback.

4. Feedback & Progress
   - Adaptive progression, challenges, badges, and certifications.

---

## ğŸ“Š Workflow Diagram

![Workflow](images/workflow.png)

---

## ğŸ“· User Testing (Early)

- Beginners completed tasks faster with voice than with traditional VR menus.
- Children and adults adapted quickly to task-driven, conversational guidance.
- Dynamic difficulty and timely feedback increased engagement.

![User Testing](images/Test%201.jpg)
![User Testing](images/Test%202.jpg)
![User Testing](images/Test%203.jpg)
![User Testing](images/Test%204.jpg)
![User Testing](images/Test%205.jpg)

---

## ğŸŒ Impact

- Bridges formal TVET and real-world workshops.
- Makes training accessible in local languages with adaptive pacing.
- Scalable model for global, hands-on skills training in VR.

---

## ğŸ”§ Requirements & Notes

- Platform: PCVR (tested with PC-powered headsets).
- Audio: Headset mic recommended for accurate ASR; captions available.
- Noisy environments: Prefer push-to-talk and/or controller fallback.

---

## ğŸ”— About the Project

Built with Unreal Engine and integrated AI for adaptive tutoring and natural interactions. Voice is the primary interaction method; controllers are supported for accessibility and fallback.